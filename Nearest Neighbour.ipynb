{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a012aab2",
   "metadata": {},
   "source": [
    "# Nearest Neighbour\n",
    "\n",
    "The purpose of this sectionn is to use nearest neighbour algorithm to predict house price. First, import and load source data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb82d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsRegressor\n",
    "\n",
    "path = './archive/'\n",
    "\n",
    "kc_data = pd.read_csv(path + '/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901906fa",
   "metadata": {},
   "source": [
    "Clean data. Remove obviously wrong record with 33 bedrooms, detected in \"Outlier checking.ipynb\". Then split data into train, test, final test data by 60/20/20 ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "351253d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = kc_data.drop(['id','date'],axis = 1)\n",
    "#remove obviously wrong record with 33 bedrooms, detected in \"Outlier checking.ipynb\"\n",
    "data = data.drop(labels=15870, axis=0) \n",
    "\n",
    "y = data['price']\n",
    "X = data.drop('price', axis=1)\n",
    "\n",
    "# split the train, test and final test data\n",
    "X_train, X_final_test, y_train, y_final_test = train_test_split(X, y, test_size=0.2, random_state=42) \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.25, random_state=42) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72645f45",
   "metadata": {},
   "source": [
    "#-------------above: data clean and split--------------------------------------------\n",
    "\n",
    "Then transform input data by standard normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8477a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(X):\n",
    "        X_new = stats.zscore(X)\n",
    "        X_mean = np.average(X, axis=0)\n",
    "        X_sigma = np.var(X, axis=0)**0.5\n",
    "        return X_new, X_mean, X_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f6768c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm, X_train_mean, X_train_sigma = norm(X_train)\n",
    "X_test_norm, X_test_mean, X_test_sigma = norm(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88305492",
   "metadata": {},
   "source": [
    "Then fit to nearest neighbour model. Select KD tree algorithm for the model as it is good for large number of samples with dimension < 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "478ae7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for k=1: 0.7005855495690386\n",
      "R2 for k=2: 0.7592114295539327\n",
      "R2 for k=3: 0.7774861182320841\n",
      "R2 for k=4: 0.7806656321890751\n",
      "R2 for k=5: 0.7836042908088774\n",
      "R2 for k=6: 0.7824438412445217\n",
      "R2 for k=7: 0.7843952394509026\n",
      "R2 for k=8: 0.7837599077635617\n",
      "R2 for k=9: 0.7830045977629589\n",
      "R2 for k=10: 0.7835484054437615\n",
      "R2 for k=11: 0.7843376108619008\n",
      "R2 for k=12: 0.7825429123491603\n",
      "R2 for k=13: 0.7816034498764851\n",
      "R2 for k=14: 0.7819417775555662\n",
      "R2 for k=15: 0.7811160239055794\n",
      "R2 for k=16: 0.7784664752036163\n",
      "R2 for k=17: 0.778367886448687\n",
      "R2 for k=18: 0.77619155250444\n",
      "R2 for k=19: 0.775395468224563\n",
      "R2 for k=20: 0.7746720561652046\n"
     ]
    }
   ],
   "source": [
    "for k in range(1,21):\n",
    "    neigh = KNeighborsRegressor(n_neighbors=k, weights='distance', algorithm='kd_tree')\n",
    "    neigh.fit(X_train_norm, y_train)\n",
    "    print(\"R2 for k=\"+str(k)+\": \"+str(neigh.score(X_test_norm, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cbf6c0",
   "metadata": {},
   "source": [
    "From above, the best score is 78.44% for k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "918f7961",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_neigh = neigh.kneighbors(X_test_norm, return_distance=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8995d445",
   "metadata": {},
   "source": [
    "Above line is to get the neighbour points. What if we combine and use linear regression for neighbour points instead of just an average over these points? Let's have first trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "95c42dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.70049729 -0.15281684  0.92981188 -0.05545212 -0.0027696  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  1.38359559 -0.65538417 -0.21151453\n",
      "  -0.21205709  0.26781398 -1.91088736  0.18483703 -0.0393768  -0.06849211]\n",
      " [ 1.81438591  0.82357436  0.90792454  0.03051201 -0.0027696  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  1.35932534 -0.65538417 -0.14352996\n",
      "  -0.21205709 -0.37059166 -0.86860437  0.48225448 -0.01003497  0.17411628]\n",
      " [ 0.70049729  0.17264689  0.06526164 -0.13883973  0.9180156  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  0.42492069 -0.65538417  0.50232341\n",
      "  -0.21205709  0.26781398 -2.13335664 -0.03468538  0.06331961 -0.17382802]\n",
      " [ 1.81438591  0.49811062  0.99547393 -0.18904567  0.9180156  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  1.45640634 -0.65538417  0.63829254\n",
      "  -0.21205709 -0.67101785 -1.44355743  0.86464835  0.23937061 -0.16204026]\n",
      " [ 1.81438591  0.49811062  0.60150166 -0.16067992 -0.0027696  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  1.01954183 -0.65538417 -0.10953768\n",
      "  -0.21205709 -1.42208331 -1.97878383  0.12110472 -0.3034533  -0.14884758]\n",
      " [ 0.70049729 -0.47828058  0.67810738 -0.17500727 -0.0027696  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  1.10448771 -0.65538417 -0.10953768\n",
      "  -0.21205709 -0.37059166 -0.76748197  0.48933585  0.34206703 -0.17283428]\n",
      " [ 0.70049729  0.17264689  0.32790981 -0.1792212   0.9180156  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  0.7161637  -0.65538417  0.19639286\n",
      "  -0.21205709 -0.42692157 -0.87510509  0.13526745  0.16601603 -0.17883096]\n",
      " [ 0.70049729  0.17264689  1.01736128 -0.10156453  0.9180156  -0.08681874\n",
      "  -0.30730473  0.91485881  1.14029233  1.4806766  -0.65538417  0.57030797\n",
      "  -0.21205709  0.26781398 -1.64435762  0.08569788  1.0316001  -0.06832078]\n",
      " [ 0.70049729  0.17264689  0.63433269 -0.09494264  0.9180156  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  1.05594721 -0.65538417  0.02643145\n",
      "  -0.21205709 -0.35181503 -0.63602286  0.58139363  0.15134511 -0.06163877]\n",
      " [ 0.70049729  0.49811062  0.62338901 -0.13705784  0.9180156  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  1.04381208 -0.65538417  0.74026938\n",
      "  -0.21205709 -0.67101785 -1.37927247  0.59555637  0.76752361 -0.13942423]\n",
      " [ 0.70049729  0.82357436  0.57961432 -0.14871236  0.9180156  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  0.99527158 -0.65538417  0.63829254\n",
      "  -0.21205709 -0.67101785 -1.34026812  0.63096321  0.59147261 -0.17362242]\n",
      " [ 1.81438591  0.49811062  0.2075294  -0.21293262  0.9180156  -0.08681874\n",
      "  -0.30730473 -0.62147837  0.28837471  0.58267732 -0.65538417  0.80825395\n",
      "  -0.21205709  0.26781398 -1.68769579  0.31230165  0.37140886 -0.20264633]\n",
      " [ 0.70049729  0.17264689  0.27319144 -0.09012672 -0.9235548  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  0.65548807 -0.65538417  0.09441602\n",
      "  -0.21205709 -0.37059166 -0.7999856   0.46101038  0.95824552 -0.09316415]\n",
      " [ 1.81438591  0.82357436  0.53583962 -0.18981622  0.9180156  -0.08681874\n",
      "  -0.30730473 -0.62147837  0.28837471  0.94673108 -0.65538417  0.84224623\n",
      "  -0.21205709  0.26781398 -2.15285881  0.00780283  0.31272519 -0.18839137]\n",
      " [ 0.70049729  0.17264689  0.14186736 -0.08290285  0.9180156  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  0.50986657 -0.65538417 -0.14352996\n",
      "  -0.21205709 -0.85878421 -1.4117761  -0.50205566  0.07799053 -0.13428422]\n",
      " [ 0.70049729  0.49811062  0.05431796 -0.1148083   0.9180156  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  0.41278556 -0.65538417  0.50232341\n",
      "  -0.21205709 -0.37059166 -0.88232812  0.37603396  0.34206703 -0.15114345]\n",
      " [ 1.81438591  0.82357436  0.34979716 -0.17079334  0.9180156  -0.08681874\n",
      "  -0.30730473 -0.62147837  0.28837471  0.74043395 -0.65538417  0.9102308\n",
      "  -0.21205709  0.26781398 -2.14346888  0.02904693  0.60614352 -0.1668376 ]\n",
      " [ 0.70049729  0.17264689 -0.07700613  0.09287815  0.9180156  -0.08681874\n",
      "  -0.30730473  0.91485881  0.28837471  0.26716406 -0.65538417  0.1284083\n",
      "  -0.21205709 -0.67101785 -1.34965806  0.66637005 -0.05404772  0.22983397]\n",
      " [ 0.70049729  0.17264689  0.66716371  0.50497622  0.9180156  -0.08681874\n",
      "  -0.30730473  0.91485881  1.14029233  1.09235258 -0.65538417  0.50232341\n",
      "  -0.21205709  0.26781398 -1.80326424  0.68761415  0.85554911  0.75976884]\n",
      " [ 0.70049729  0.49811062  0.19658573 -0.03341929 -0.9235548  -0.08681874\n",
      "  -0.30730473  0.91485881  1.14029233  0.57054219 -0.65538417  0.1284083\n",
      "  -0.21205709 -0.67101785 -1.32582206  0.36895259  0.97291644  0.02505604]]\n",
      "[294000. 410000. 322500. 339950. 270000. 390000. 365650. 433495. 425000.\n",
      " 397450. 372000. 285000. 375000. 329000. 336000. 435000. 327000. 322200.\n",
      " 460000. 350000.]\n",
      "intercept: 2.33203813335334e+17; coef: [-2.72412212e+04  2.10078234e+03 -2.82285793e+17  2.57739403e+05\n",
      " -2.36282317e+04  1.76988513e+17 -3.00064180e+17  1.59759603e+04\n",
      "  2.14959893e+04  2.54570399e+17  6.34691969e+17  1.73805275e+05\n",
      " -7.62447278e+16  2.11248511e+03  1.21822551e+05 -9.34899445e+04\n",
      " -5.15927500e+04 -1.58056368e+04]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.24710544e+16])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_np = (y_train).to_numpy()\n",
    "\n",
    "X_in = X_train_norm[X_test_neigh[0]]\n",
    "y_in = y_np[X_test_neigh[0]]\n",
    "print(X_in)\n",
    "print(y_in)\n",
    "reg=LinearRegression().fit(X_in, y_in)\n",
    "print(\"intercept: \"+str(reg.intercept_)+\"; coef: \"+str(reg.coef_))\n",
    "\n",
    "reg.predict(X_test_norm[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "979446e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: -1.2085540425412828e-14; coef: [-0.09930007  0.10377816  0.23060216  0.00517823  0.01613386  0.14345411\n",
      "  0.10632847  0.04102515  0.29434998  0.21008498  0.08481163 -0.22573833\n",
      "  0.02536397 -0.08093204  0.22477773 -0.06779121  0.03083645 -0.0212118 ]\n"
     ]
    }
   ],
   "source": [
    "reg_train=LinearRegression().fit(X_train_norm, stats.zscore(y_train))\n",
    "print(\"intercept: \"+str(reg_train.intercept_)+\"; coef: \"+str(reg_train.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18d7734",
   "metadata": {},
   "source": [
    "The frist trial of combining with linear regreesion has poor performance. Let's examine further.\n",
    "Small coefficients may imply insignificance of corresponding variables. As nearest neighbour method does not give different weight to each dimension, including feature that is not important may hurt the influence of other important features and overall performance. Try again by dropping sqft_lot, floors, yr_renovated, sqft_living15, sqft_lot15, or try each one generally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb67fe69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for k=6, drop bedrooms: 0.7975429546890449\n",
      "R2 for k=10, drop bathrooms: 0.7954220854144363\n",
      "R2 for k=9, drop sqft_living: 0.7762594473811026\n",
      "R2 for k=14, drop sqft_lot: 0.7833599265897042\n",
      "R2 for k=8, drop floors: 0.7899579497307077\n",
      "R2 for k=8, drop waterfront: 0.7838341129683302\n",
      "R2 for k=6, drop view: 0.7974347523050592\n",
      "R2 for k=6, drop condition: 0.7937152075021774\n",
      "R2 for k=11, drop grade: 0.762063498760535\n",
      "R2 for k=6, drop sqft_above: 0.7795195212009083\n",
      "R2 for k=8, drop sqft_basement: 0.7964918854811512\n",
      "R2 for k=9, drop yr_built: 0.7824780945597906\n",
      "R2 for k=5, drop yr_renovated: 0.7824276983253649\n",
      "R2 for k=5, drop zipcode: 0.779982255648137\n",
      "R2 for k=10, drop lat: 0.7253785710594872\n",
      "R2 for k=11, drop long: 0.7678089112264762\n",
      "R2 for k=9, drop sqft_living15: 0.7807885550096539\n",
      "R2 for k=7, drop sqft_lot15: 0.7846214974084792\n"
     ]
    }
   ],
   "source": [
    "#X_train_drop = X_train.drop(['sqft_lot','floors','yr_renovated','sqft_living15','sqft_lot15'], axis=1)\n",
    "#X_test_drop = X_test.drop(['sqft_lot','floors','yr_renovated','sqft_living15','sqft_lot15'], axis=1)\n",
    "\n",
    "max_score={}\n",
    "max_score_k={}\n",
    "for feature in X_train.columns:  \n",
    "    max_score[feature]=0\n",
    "    max_score_k[feature]=0\n",
    "    for k in range(1,21):\n",
    "        X_train_drop = X_train.drop([feature], axis=1)\n",
    "        X_test_drop = X_test.drop([feature], axis=1)\n",
    "        neigh = KNeighborsRegressor(n_neighbors=k, weights='distance', algorithm='kd_tree')\n",
    "        neigh.fit(stats.zscore(X_train_drop), y_train)\n",
    "        temp = neigh.score(stats.zscore(X_test_drop), y_test)\n",
    "        if temp > max_score[feature]:\n",
    "            max_score[feature]=temp\n",
    "            max_score_k[feature]=k\n",
    "    print(\"R2 for k=\"+str(max_score_k[feature])+\", drop \"+feature+\": \"+str(max_score[feature]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23adf7",
   "metadata": {},
   "source": [
    "From above, generally droping one feature may not improve the score much, and it may hurt performance for dropping some important feature, notably such as lat, long, sqft_living, grade. Let's see what if only lat, long, sqft_living, grade are included?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f6723e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5385006155130563\n"
     ]
    }
   ],
   "source": [
    "X_train_drop = X_train[['lat','long']]\n",
    "X_test_drop = X_test[['lat', 'long']]\n",
    "neigh = KNeighborsRegressor(n_neighbors=9, weights='distance', algorithm='kd_tree')\n",
    "neigh.fit(stats.zscore(X_train_drop), y_train)\n",
    "print(neigh.score(stats.zscore(X_test_drop), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d9db56ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7863816045518219\n"
     ]
    }
   ],
   "source": [
    "X_train_drop = X_train[['sqft_living','lat','long']]\n",
    "X_test_drop = X_test[['sqft_living','lat', 'long']]\n",
    "neigh = KNeighborsRegressor(n_neighbors=9, weights='distance', algorithm='kd_tree')\n",
    "neigh.fit(stats.zscore(X_train_drop), y_train)\n",
    "print(neigh.score(stats.zscore(X_test_drop), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "36dabd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8161225057554446\n"
     ]
    }
   ],
   "source": [
    "X_train_drop = X_train[['sqft_living','grade','lat','long']]\n",
    "X_test_drop = X_test[['sqft_living','grade','lat', 'long']]\n",
    "neigh = KNeighborsRegressor(n_neighbors=9, weights='distance', algorithm='kd_tree')\n",
    "neigh.fit(stats.zscore(X_train_drop), y_train)\n",
    "print(neigh.score(stats.zscore(X_test_drop), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be02766",
   "metadata": {},
   "source": [
    "We should note that only lat, long already gives the same performance vs all the features! \n",
    "\n",
    "And it may help if only add some more features selectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aab3ee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waterfront added to sqft_living, lat, long. R2 score: 0.821509437622671\n",
      "yr_built added to sqft_living, lat, long. R2 score: 0.796920115328263\n",
      "sqft_basement added to sqft_living, lat, long. R2 score: 0.7719446241452717\n",
      "view added to sqft_living, lat, long. R2 score: 0.8047982179218391\n",
      "sqft_lot added to sqft_living, lat, long. R2 score: 0.8021446280084724\n",
      "sqft_above added to sqft_living, lat, long. R2 score: 0.7843511287039105\n",
      "yr_renovated added to sqft_living, lat, long. R2 score: 0.7878778863105822\n",
      "zipcode added to sqft_living, lat, long. R2 score: 0.7849201260325311\n",
      "sqft_lot15 added to sqft_living, lat, long. R2 score: 0.7992146886212602\n",
      "bedrooms added to sqft_living, lat, long. R2 score: 0.7790371290613699\n",
      "sqft_living15 added to sqft_living, lat, long. R2 score: 0.8010795758186134\n",
      "floors added to sqft_living, lat, long. R2 score: 0.7855795667937342\n",
      "bathrooms added to sqft_living, lat, long. R2 score: 0.7674873434583119\n",
      "grade added to sqft_living, lat, long. R2 score: 0.8161225057554446\n",
      "condition added to sqft_living, lat, long. R2 score: 0.7803044553311679\n"
     ]
    }
   ],
   "source": [
    "for feature in set(X_train.columns) - {'sqft_living','lat','long'}:\n",
    "    X_train_drop = X_train[['sqft_living','lat','long',feature]]\n",
    "    X_test_drop = X_test[['sqft_living','lat', 'long',feature]]\n",
    "    neigh = KNeighborsRegressor(n_neighbors=9, weights='distance', algorithm='kd_tree')\n",
    "    neigh.fit(stats.zscore(X_train_drop), y_train)\n",
    "    print(feature+\" added to sqft_living, lat, long. R2 score: \"+str(neigh.score(stats.zscore(X_test_drop), y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d2b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
